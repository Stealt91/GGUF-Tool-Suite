# Token embedding and output tensors (GPU)
# note token_embd cannot be repacked quant type
output\.weight=q8_0
output_norm\.weight=q8_0
token_embd\.weight=q8_0

# GPU Only - not divisible by 256 so only supports qN_0
blk\.([0-9]|[1-5][0-9]|60)\.attn_k_b\.weight=q8_0

# GPU Only
blk\.([0-9]|[1-5][0-9]|60)\.attn_v_b\.weight=q8_0

# GPU Only
blk\.([0-9]|[1-5][0-9]|60)\.attn_kv_b\.weight=q8_0

# GPU Only
blk\.([0-9]|[1-5][0-9]|60)\.attn_kv_a_norm\.weight=q8_0
blk\.([0-9]|[1-5][0-9]|60)\.attn_q_a\.weight=q8_0
blk\.([0-9]|[1-5][0-9]|60)\.attn_q_a_norm\.weight=q8_0
blk\.([0-9]|[1-5][0-9]|60)\.attn_q_b\.weight=q8_0
blk\.([0-9]|[1-5][0-9]|60)\.attn_norm\.weight=q8_0
blk\.([0-9]|[1-5][0-9]|60)\.attn_output\.weight=q8_0
blk\.([3-9]|[1-5][0-9]|60)\.exp_probs_b\.bias=q8_0

# GPU Only
blk\.([0-9]|[1-5][0-9]|60)\.attn_kv_a_mqa\.weight=q8_0

# GPU Only
blk\.[0-2]\.ffn_down\.weight=q8_0
blk\.[0-2]\.ffn_gate\.weight=q8_0
blk\.([3-9]|[1-5][0-9]|60)\.ffn_gate_inp\.weight=q8_0
blk\.([0-9]|[1-5][0-9]|60)\.ffn_norm\.weight=q8_0
blk\.[0-2]\.ffn_up\.weight=q8_0

## Isolate ffn_*_shexp
blk\.([3-9]|[1-5][0-9]|60)\.ffn_down_shexp\.weight=iq3_xxs
blk\.([3-9]|[1-5][0-9]|60)\.ffn_gate_shexp\.weight=iq3_xxs
blk\.([3-9]|[1-5][0-9]|60)\.ffn_up_shexp\.weight=iq3_xxs

## GPU+CPU - use iQuants!
blk\.([3-9]|[1-5][0-9]|60)\.ffn_down_exps\.weight=iq3_xxs
blk\.([3-9]|[1-5][0-9]|60)\.ffn_gate_exps\.weight=iq3_xxs
blk\.([3-9]|[1-5][0-9]|60)\.ffn_up_exps\.weight=iq3_xxs