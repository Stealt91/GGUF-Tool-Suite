{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Recipe Pipeline\n",
                "Configure your parameters below, then run all cells ▶️"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "98aa646d",
            "metadata": {
                "id": "params"
            },
            "outputs": [],
            "source": [
                "# @title ⚙️ Pipeline Parameters\n",
                "repo_url = \"https://github.com/Thireus/GGUF-Tool-Suite.git\"         #@param {type:\"string\"}\n",
                "model_name = \"DeepSeek-R1-0528\"                                     #@param {type:\"string\"}\n",
                "model_link = \"https://huggingface.co/deepseek-ai/DeepSeek-R1-0528\"  #@param {type:\"string\"}\n",
                "\n",
                "# regex lists (as Python lists of strings)\n",
                "gpu_tensors = [r\".*\"]    #@param {type:\"raw\"}\n",
                "cpu_tensors = [r\"blk\\.([3-9]|[1-5][0-9]|60)\\.ffn_down_exps\\.weight\", r\"blk\\.([3-9]|[1-5][0-9]|60)\\.ffn_up_exps\\.weight\", r\"blk\\.([3-9]|[1-5][0-9]|60)\\.ffn_gate_exps\\.weight\"]   #@param {type:\"raw\"}\n",
                "\n",
                "# quant types\n",
                "cpu_quants = [\"iq4_ks\", \"iq3_k\", \"iq2_k\", \"iq1_m_r4\"]   #@param {type:\"raw\"}\n",
                "gpu_quants = [\"q8_0\", \"iq5_k_r4\", \"iq6_k\"]              #@param {type:\"raw\"}\n",
                "\n",
                "# sizes & tuning\n",
                "cpu_tensors_max_size = \"230\"       #@param {type:\"string\"}\n",
                "gpu_tensors_max_size = \"95%\"       #@param {type:\"string\"}\n",
                "tolerance = 0.01                #@param {type:\"number\"}\n",
                "exponential_factor = 8          #@param {type:\"integer\"}\n",
                "\n",
                "# assignment override\n",
                "gpu_assign_qtype = \"iq4_xs\"    #@param {type:\"string\"}\n",
                "gpu_assign_tensors = [r\"blk\\.([0-9]|[1-5][0-9]|60)\\.attn_k_b\\.weight=q8_0\"] #@param {type:\"raw\"}\n",
                "cpu_assign_qtype = None         #@param {type:\"raw\"}\n",
                "cpu_assign_tensors = []         #@param {type:\"raw\"}\n",
                "\n",
                "# additional flags\n",
                "debug = False              #@param {type:\"boolean\"}\n",
                "info = False                #@param {type:\"boolean\"}\n",
                "ignore_f32 = False         #@param {type:\"boolean\"}\n",
                "tensors_from_csv = False   #@param {type:\"boolean\"}\n",
                "cpu_irq_k = 1.5            #@param {type:\"number\"}\n",
                "gpu_irq_k = 1.5            #@param {type:\"number\"}\n",
                "skip_gpg = False              #@param {type:\"boolean\"}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a1e3dd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd ~\n",
                "!rm -rf GGUF-Tool-Suite # Clear all the things"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2568d92f",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash -e -s \"$repo_url\" \"$model_name\"\n",
                "REPO_URL=\"$1\"\n",
                "MODEL_NAME=\"$2\"\n",
                "\n",
                "# 1) Clone (if needed) and cd into repo\n",
                "if [ ! -d GGUF-Tool-Suite ]; then\n",
                "  echo \"↳ GGUF-Tool-Suite not found; cloning from $REPO_URL...\"\n",
                "  git clone \"$REPO_URL\" \\\n",
                "    || { echo \"❌ ERROR: failed to clone GGUF-Tool-Suite. Aborting.\"; exit 1; }\n",
                "fi\n",
                "cd GGUF-Tool-Suite\n",
                "\n",
                "# 2) Verify model directory exists\n",
                "if [ ! -d models/$MODEL_NAME ]; then\n",
                "  echo \"❌ ERROR: models/$MODEL_NAME not found; this model is not supported yet.\"\n",
                "  exit 1\n",
                "fi\n",
                "\n",
                "# 3) Link download.conf (or abort if missing)\n",
                "if [ -f models/$MODEL_NAME/download.conf ]; then\n",
                "  ln -sf models/$MODEL_NAME/download.conf .\n",
                "else\n",
                "  echo \"❌ ERROR: download.conf for '$MODEL_NAME' missing; this model isn't meant to be used here.\"\n",
                "  exit 1\n",
                "fi\n",
                "\n",
                "# 4) Link ppl_results.csv (or abort with warning)\n",
                "if [ -f models/$MODEL_NAME/ppl_results.csv ]; then\n",
                "  ln -sf models/$MODEL_NAME/ppl_results.csv .\n",
                "elif [ -f models/$MODEL_NAME/ppl_results_partial.csv ]; then\n",
                "  rm -f ppl_results.csv\n",
                "  ln -sf models/$MODEL_NAME/ppl_results_partial.csv .\n",
                "  echo \"⚠️ WARNING: partial calibrated ppl_results_partial.csv found for '$MODEL_NAME; will try to interpolate missing results as best as we can, but this will unlikely produce ppl-optimum quant mixes (so please don't use for production) - full calibrated data likely coming soon.\"\n",
                "else\n",
                "  echo \"❌ ERROR: ppl_results.csv (and ppl_results_partial.csv) missing; support for '$MODEL_NAME' likely coming soon.\"\n",
                "  exit 1\n",
                "fi\n",
                "\n",
                "# 5) Make all scripts executable\n",
                "chmod +x *.sh *.py\n",
                "\n",
                "# 6) Link download.conf\n",
                "if [ -f models/$MODEL_NAME/download.conf ]; then\n",
                "  ln -sf models/$MODEL_NAME/download.conf .\n",
                "else\n",
                "  echo \"❌ ERROR: download.conf not found for '$MODEL_NAME'; support for '$MODEL_NAME' likely coming soon.\"\n",
                "  exit 1\n",
                "fi\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cde5856a",
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd GGUF-Tool-Suite/models/{model_name}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22fa5266",
            "metadata": {},
            "outputs": [],
            "source": [
                "!if [ -f ppl_results.csv ]; then \\\n",
                "    echo \"Complete ppl_results.csv already exists. Skipping interpolation...\"; \\\n",
                "elif [ -f ppl_results_partial.csv ]; then \\\n",
                "    echo \"Interpolation of ppl_results.csv necessary.\"; \\\n",
                "    python ../../fill_missing_ppl.py ppl_results_partial.csv; \\\n",
                "else \\\n",
                "    echo \"Error: No ppl results found. Aborting.\"; \\\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6ebfc19b",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install pgpy # Install dependency to validate gpg signatures"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c336d64d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, glob\n",
                "import shlex, subprocess\n",
                "\n",
                "def add_flag(cmd, key, val):\n",
                "    if isinstance(val, bool):\n",
                "        if val:\n",
                "            cmd.append(f\"--{key}\")\n",
                "    elif val is not None:\n",
                "        cmd.extend([f\"--{key}\", str(val)])\n",
                "\n",
                "def add_list_flag(cmd, key, vals):\n",
                "    if vals:\n",
                "        cmd.append(f\"--{key}\")\n",
                "        cmd.extend(vals)\n",
                "\n",
                "# Determine which file to use\n",
                "if os.path.isfile(\"ppl_results.csv\"):\n",
                "    input_file = \"ppl_results.csv\"\n",
                "else:\n",
                "    # Search for the first matching file in the current directory\n",
                "    partial_files = glob.glob(\"ppl_results_partial_*interpolated.csv\")\n",
                "    if partial_files:\n",
                "        input_file = sorted(partial_files)[0]  # Use the first one alphabetically\n",
                "    else:\n",
                "        raise FileNotFoundError(\"No suitable input file found: ppl_results.csv, ppl_results_interpolated.csv, or ppl_results_partial_*interpolated.csv\")\n",
                "\n",
                "cmd = [\"python\", \"../../quant_assign.py\", input_file]\n",
                "\n",
                "add_flag(cmd, \"tolerance\", tolerance)\n",
                "add_flag(cmd, \"cpu-irq-k\", cpu_irq_k)\n",
                "add_flag(cmd, \"gpu-irq-k\", gpu_irq_k)\n",
                "add_flag(cmd, \"qtype\", None)\n",
                "add_flag(cmd, \"cpu-assign-qtype\", cpu_assign_qtype)\n",
                "add_flag(cmd, \"gpu-assign-qtype\", gpu_assign_qtype)\n",
                "add_flag(cmd, \"cpu-tensors-max-size\", cpu_tensors_max_size)\n",
                "add_flag(cmd, \"gpu-tensors-max-size\", gpu_tensors_max_size)\n",
                "add_flag(cmd, \"exponential-factor\", exponential_factor)\n",
                "add_flag(cmd, \"debug\", debug)\n",
                "add_flag(cmd, \"info\", info)\n",
                "add_flag(cmd, \"ignore-f32\", ignore_f32)\n",
                "add_flag(cmd, \"tensors-from-csv\", tensors_from_csv)\n",
                "add_flag(cmd, \"skip-gpg\", skip_gpg)\n",
                "\n",
                "add_list_flag(cmd, \"cpu-tensors\", cpu_tensors)\n",
                "add_list_flag(cmd, \"gpu-tensors\", gpu_tensors)\n",
                "add_list_flag(cmd, \"cpu-quants\", cpu_quants)\n",
                "add_list_flag(cmd, \"gpu-quants\", gpu_quants)\n",
                "add_list_flag(cmd, \"cpu-assign-tensors\", cpu_assign_tensors)\n",
                "add_list_flag(cmd, \"gpu-assign-tensors\", gpu_assign_tensors)\n",
                "\n",
                "# Print for verification\n",
                "print(\"\\nRunning quant_assign.py command:\")\n",
                "print(\" \".join(shlex.quote(c) for c in cmd))\n",
                "\n",
                "# Run quant_assign.py\n",
                "result = subprocess.run(cmd, capture_output=True, text=True)\n",
                "\n",
                "# Print stderr and stdout for debugging\n",
                "print(\"quant_assign.py stdout:\", result.stdout)\n",
                "print(\"quant_assign.py stderr:\", result.stderr)\n",
                "\n",
                "if result.returncode != 0:\n",
                "    print(\"quant_assign.py failed:\", result.stderr)\n",
                "    raise SystemExit(1)\n",
                "\n",
                "# Merge regex\n",
                "merge_cmd = [\n",
                "    \"bash\", \"../../quants_regex_merger.sh\",\n",
                "    \"--model-name\", model_name,\n",
                "    \"--add-ppl\", \"0\",\n",
                "    \"--model-link\", model_link\n",
                "]\n",
                "merge = subprocess.run(merge_cmd, input=result.stdout, capture_output=True, text=True)\n",
                "\n",
                "# Print final output\n",
                "print(merge.stdout)\n",
                "\n",
                "if merge.returncode != 0:\n",
                "    print(\"quants_regex_merger.sh failed\")\n",
                "    raise SystemExit(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "637edb2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "from google.colab import files\n",
                "\n",
                "# List all .recipe files matching the prefix\n",
                "recipe_files = glob.glob(f\"{model_name}*.recipe\")\n",
                "\n",
                "# Print the found files\n",
                "print(\"Downloading .recipe file:\")\n",
                "for file in recipe_files:\n",
                "    print(f\"- {file}\")\n",
                "\n",
                "# Auto‑start download\n",
                "for file in recipe_files:\n",
                "    files.download(file)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
