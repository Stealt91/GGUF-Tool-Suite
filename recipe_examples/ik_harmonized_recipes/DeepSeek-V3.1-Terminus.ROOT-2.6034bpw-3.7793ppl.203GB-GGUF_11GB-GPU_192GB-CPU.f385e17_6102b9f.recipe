## Quant mix recipe created using Thireus' GGUF Tool Suite - https://gguf.thireus.com/
# Model name: DeepSeek-V3.1-Terminus
# Link to the original model: https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus

## Model head & embeddings — qbits: 32 8 
^output_norm\.weight$=f32
^token_embd\.weight$=q8_0
^output\.weight$=q8_0

## Special attention kernels — single-quant only (llama-quantize takes care of it) — qbits: 8 
^blk\.([0-9]|[1-5][0-9]|60)\.attn_k_b\.weight$=q8_0

## Multi-headed attention parameters — qbits: 32 4 
^blk\.([0-9]|[1-5][0-9]|60)\.attn_q_a\.weight$=iq4_ks
^blk\.([0-9]|[1-5][0-9]|60)\.attn_output\.weight$=iq4_ks
^blk\.([0-9]|[1-5][0-9]|60)\.attn_kv_a_norm\.weight$=f32
^blk\.([0-9]|[1-5][0-9]|60)\.attn_v_b\.weight$=iq4_ks
^blk\.([0-9]|[1-5][0-9]|60)\.attn_q_b\.weight$=iq4_ks
^blk\.([0-9]|[1-5][0-9]|60)\.attn_kv_a_mqa\.weight$=iq4_ks
^blk\.([0-9]|[1-5][0-9]|60)\.attn_q_a_norm\.weight$=f32
^blk\.([0-9]|[1-5][0-9]|60)\.attn_norm\.weight$=f32

## Core FFN weights — qbits: 32 8 6 
^blk\.([3-9]|[1-5][0-9]|60)\.ffn_gate_inp\.weight$=f32
^blk\.[0-2]\.ffn_down\.weight$=iq6_k
^blk\.([0-9]|[1-5][0-9]|60)\.ffn_norm\.weight$=f32
^blk\.[0-1]\.ffn_gate\.weight$=q8_0
^blk\.2\.ffn_gate\.weight$=iq6_k
^blk\.2\.ffn_up\.weight$=iq6_k
^blk\.[0-1]\.ffn_up\.weight$=q8_0

## Other tensors — qbits: 32 
^blk\.([3-9]|[1-5][0-9]|60)\.exp_probs_b\.bias$=f32

## GPU-loaded ffn_*_shexp
# ffn_down_shexp (down-projection) — qbits: 8 6 5 
^blk\.(8|1[2-3]|21|24|27|29|30|34|3[6-9]|41|4[5-6]|60)\.ffn_down_shexp\.weight$=q8_0
^blk\.([3-5]|7|9|1[0-1]|1[4-9]|23|2[5-6]|28|3[1-3]|35|40|4[2-4]|4[7-9]|5[1-2])\.ffn_down_shexp\.weight$=iq6_k
^blk\.(6|20|22|50|5[3-9])\.ffn_down_shexp\.weight$=iq5_ks_r4

# ffn_up_shexp (up-projection) — qbits: 8 6 5 
^blk\.([3-4]|[8-9]|12|1[5-7]|23|2[6-7]|30|3[3-4]|37|45|60)\.ffn_up_shexp\.weight$=q8_0
^blk\.(5|7|1[0-1]|1[3-4]|1[8-9]|2[0-2]|2[4-5]|2[8-9]|3[1-2]|3[5-6]|3[8-9]|4[0-4]|4[6-8]|5[0-4])\.ffn_up_shexp\.weight$=iq6_k
^blk\.(6|49|5[5-9])\.ffn_up_shexp\.weight$=iq5_ks_r4

# ffn_gate_shexp (gate-projection) — qbits: 8 6 5 
^blk\.(3|6|9|10|13|1[7-8]|21|2[3-8]|32|39|4[8-9]|60)\.ffn_gate_shexp\.weight$=q8_0
^blk\.([4-5]|8|11|1[4-6]|19|20|22|29|3[0-1]|3[3-8]|4[0-7]|5[0-1]|5[3-6]|59)\.ffn_gate_shexp\.weight$=iq6_k
^blk\.(7|12|52|5[7-8])\.ffn_gate_shexp\.weight$=iq5_ks_r4

## CPU-friendly ffn_*_exps
# ffn_down_exps (down-extraction) — qbits: 4 3 2 
^blk\.(3[2-5]|37|39|4[0-2]|44|46|4[8-9])\.ffn_down_exps\.weight$=iq4_kt
^blk\.(18|23|26|28|30|36|38|45|47|5[0-5])\.ffn_down_exps\.weight$=iq3_kt
^blk\.([3-9]|1[0-7]|19|2[0-2]|2[4-5]|27|29|31|43|5[6-9]|60)\.ffn_down_exps\.weight$=iq2_kt

# ffn_up_exps (up-extraction) — qbits: 3 2 
^blk\.(3[4-5]|37|39|40|4[3-4]|46|48|5[0-3]|5[5-6])\.ffn_up_exps\.weight$=iq3_kt
^blk\.([3-9]|[1-2][0-9]|3[0-3]|36|38|4[1-2]|45|47|49|54|5[7-9]|60)\.ffn_up_exps\.weight$=iq2_kt

# ffn_gate_exps (gate-extraction) — qbits: 3 2 
^blk\.(3[4-5]|37|39|40|4[3-4]|46|48|5[0-3]|5[5-6])\.ffn_gate_exps\.weight$=iq3_kt
^blk\.([3-9]|[1-2][0-9]|3[0-3]|36|38|4[1-2]|45|47|49|54|5[7-9]|60)\.ffn_gate_exps\.weight$=iq2_kt

## Summary of tensor sizes per class
# GPU Total: 11.253 GiB (95.1%) | 11.84 GiB max, if all were q8_0 | 9.72 GiB min, if all were iq5_ks_r4
# CPU Total: 192.117 GiB (63.1%) | 304.50 GiB max, if all were iq4_kt | 161.77 GiB min, if all were iq2_kt
# GPU+CPU Total: 203.370 GiB (79.1%)

## Summary of tensor counts and bpw per qtype
#
# GPU-loaded quants:
# QTYPE		Count	BPW	Assigned GiB	% Assigned	Max GiB (all)
# +f32       	361	32.0  	  0.40 GiB	-		-
# +q8_0      	61 	8.5   	  0.51 GiB	-		-
# q8_0      	59 	8.5   	  3.13 GiB	56.5%		5.54
# iq6_k     	103	6.625 	  1.62 GiB	37.5%		4.32
# iq5_ks_r4 	23 	5.25  	  0.21 GiB	6.0%		3.42
# +iq4_ks    	305	4.25  	  5.39 GiB	-		-
#
# CPU-friendly quants:
# QTYPE		Count	BPW	Assigned GiB	% Assigned	Max GiB (all)
# iq4_kt    	13 	4.0   	 22.75 GiB	7.5%		304.50
# iq3_kt    	45 	3.125 	 61.52 GiB	25.9%		237.89
# iq2_kt    	116	2.125 	107.84 GiB	66.7%		161.77
#
# -Average BPW: 2.6034
#
# -Notes:
# - '+' means user-defined pre-assigned tensors, or tensor missing from csv data or f32 tensors
# - Recipe produced on the 2025-09-28 07:57:21 UTC+0000 using Thireus' GGUF tools (https://gguf.thireus.com/)
# - Script SHA-256: f385e17ea9998140203cc543e8e9d3635f6f1292999c58d837cc6d2d3d48b1e0
# - Calibration dataset 'ppl_results.csv' SHA-256: 6e86f375f3cfc3724cc4eb748166dc1e6e4ea2e9496efdd0e1a1fbd090557d3a
# - tensors.bf16.map SHA-256: d8bc873f82ff1b42cdec2726d649dbed5b4689f1ab599c51bbb85acdc19c743c
# - tensors.bf16.map model name: DeepSeek-V3.1-Terminus-THIREUS-BF16-SPECIAL_TENSOR-01087-of-01087
# - tensors.iq4_kt.map SHA-256: 667fd06b3277226ca143df4607f7da365268112c1820670a6d7a0bf57f32a4b6
# - tensors.iq4_kt.map model name: DeepSeek-V3.1-Terminus-THIREUS-IQ4_KT-SPECIAL_TENSOR-01087-of-01087
# - tensors.iq3_kt.map SHA-256: a4099a20b0f150a6a01161d53402853ec4be960118707fc4917ce05e0148a8bf
# - tensors.iq3_kt.map model name: DeepSeek-V3.1-Terminus-THIREUS-IQ3_KT-SPECIAL_TENSOR-01087-of-01087
# - tensors.iq2_kt.map SHA-256: d6d9050651d83d5696968efc1c4702478d26f81f0a11abc106505751f65b6725
# - tensors.iq2_kt.map model name: DeepSeek-V3.1-Terminus-THIREUS-IQ2_KT-SPECIAL_TENSOR-01087-of-01087
# - tensors.q8_0.map SHA-256: 4ee954a837dcf1df29eaacbf412f2707503398839b4651b63ef7468c3f651dc5
# - tensors.q8_0.map model name: DeepSeek-V3.1-Terminus-THIREUS-Q8_0-SPECIAL_TENSOR-01087-of-01087
# - tensors.iq5_ks_r4.map SHA-256: 2c82c1a399eca049cbb55036a9c6d952d9b0bf33d527cc7523cd95cfeefabc47
# - tensors.iq5_ks_r4.map model name: DeepSeek-V3.1-Terminus-THIREUS-IQ5_KS_R4-SPECIAL_TENSOR-01087-of-01087
# - tensors.iq6_k.map SHA-256: 08c72c97c9fff653242749ff07e4f7d2df5749bda18e92b6dcc570df7ba455de
# - tensors.iq6_k.map model name: DeepSeek-V3.1-Terminus-THIREUS-IQ6_K-SPECIAL_TENSOR-01087-of-01087
# - tensors.iq1_m_r4.map SHA-256: 6808abd977c6e077ad0368c83800bad009aea9adaebdaba0b47c023c41919ed0
# - tensors.iq1_m_r4.map model name: DeepSeek-V3.1-Terminus-THIREUS-IQ1_M_R4-SPECIAL_TENSOR-01087-of-01087
# - tensors.iq4_ks.map SHA-256: f5f3aef55b13af62de6afa558be4ed72f5800ec67e7626c945d7a39c3b72611f
# - tensors.iq4_ks.map model name: DeepSeek-V3.1-Terminus-THIREUS-IQ4_KS-SPECIAL_TENSOR-01087-of-01087
# - GPG signatures: PASSED
# - Command used:
# ../../quant_assign.py ppl_results.csv --tolerance 0.01 --cpu-irq-k 1.5 --gpu-irq-k 1.5 --gpu-assign-qtype iq4_ks \
# --cpu-tensors-max-size 192 --gpu-tensors-max-size 95% --exponential-factor 8 --cpu-tensors \
# '^blk\.([3-9]|[1-5][0-9]|60)\.ffn_down_exps\.weight$' '^blk\.([3-9]|[1-5][0-9]|60)\.ffn_up_exps\.weight$' \
# '^blk\.([3-9]|[1-5][0-9]|60)\.ffn_gate_exps\.weight$' --gpu-tensors '.*' --cpu-quants iq4_kt iq3_kt iq2_kt \
# --gpu-quants q8_0 iq5_ks_r4 iq6_k --gpu-assign-tensors '^blk\.([0-9]|[1-5][0-9]|60)\.attn_k_b\.weight$=q8_0' \
# --harmonize-tensors '^blk\..*\.ffn_up_exps.*,^blk\..*\.ffn_gate_exps.*' --harmonization-technique 3

## THE END!
